{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX0HKz3X55zT"
      },
      "source": [
        "# **Mask Detection Model For Single Face Image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXfhuI6C6UaW"
      },
      "source": [
        "- **Download Pre-Trained Model and Haarcascades File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFIZ_wgq6hHY"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/kauravs1222/Face-Mask-Detector/blob/master/keras_model.h5?raw=true\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuN1IEGv_EhW"
      },
      "source": [
        "- **Upload image from your Local Device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoCOELDRd5li"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "file=files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5CYE3OS57yV"
      },
      "source": [
        "- **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGfUPK9n6Mb1"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVVtYyMD7cLd"
      },
      "source": [
        "- **Load Pre-trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJZHIJ9Y76z9"
      },
      "outputs": [],
      "source": [
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Load the model\n",
        "model = tensorflow.keras.models.load_model('keras_model.h5?raw=true', compile=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTa8EKvPeWPK"
      },
      "source": [
        "- **Or Using a webcam to capture images for processing on the runtime.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SucxddsPhOmj"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51qIu5JBd7cw"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as Image1\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image1(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmOPv9rinWlN"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR3bJoeiFBhn"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHaRmtje774f"
      },
      "source": [
        "- **Take Image and Converts it**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aqCzTvGg_vX"
      },
      "source": [
        "*Change Image Path to the image you uploaded or clicked*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaSRm7CB8bTR"
      },
      "outputs": [],
      "source": [
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "#Change path with your file path\n",
        "#Just Go to file, right click on file, copy path and paste here\n",
        "image_path = \"/content/photo.jpg\"\n",
        "\n",
        "# Replace this with the path to your image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "normal = plt.imshow(image)\n",
        "\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "\n",
        "# display the resized image\n",
        "#image.show()\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0gbXBz88cPZ"
      },
      "source": [
        "- **Predict the Image and Define Label**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0URQDok8uda"
      },
      "outputs": [],
      "source": [
        "# run the inference\n",
        "pred = model.predict(data)\n",
        "\n",
        "prediction = pred.argmax(axis=-1)\n",
        "#print(pred)\n",
        "\n",
        "label = \"Mask On\" if prediction == 0 else \"No Mask\"\n",
        "label = \"{}: {:.2f}%\".format(label, max(pred[0]) * 100)\n",
        "color = (0, 255, 0) if prediction == 0 else (255, 0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGXlaIjF8yTO"
      },
      "source": [
        "- **Detect Face and make box**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrQZ0KoK98oX"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "#print(faces)\n",
        "\n",
        "im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#Creating Box for face\n",
        "if(len(faces)!=0):\n",
        "  for (x,y,w,h) in faces:\n",
        "      cv2.rectangle(im_rgb,(x,y),(x+w,y+h),color, 4)\n",
        "      #cv2.rectangle(im_rgb, (x,y), (x+w,y-35), color, cv2.FILLED)\n",
        "      cv2.putText(im_rgb, label, (x+5, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
        "   \n",
        "else:\n",
        "  cv2.rectangle(im_rgb, (5, 37), (220, 5), color, cv2.FILLED)\n",
        "  cv2.putText(im_rgb, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "#detected Image\n",
        "detect = plt.imshow(im_rgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dppn3UNbry1u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}